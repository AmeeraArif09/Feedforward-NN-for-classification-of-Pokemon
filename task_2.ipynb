{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "task-2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBh-NDIYhHhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import numpy as np # linear algebra\n",
        "from tqdm import tqdm\n",
        "from scipy import ndimage\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.utils import shuffle #shuffle dataset\n",
        "from skimage.transform import rotate\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from torch.utils.data import Dataset, DataLoader #make dataset batches and load them to model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKxzDoU7hHhp",
        "colab_type": "code",
        "colab": {},
        "outputId": "21274a27-1791-47c6-9f3e-ab93ac02eddd"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Ho9W0OZBhHhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charmander = [] \n",
        "squirtle = [] \n",
        "mewtwo = [] \n",
        "bulbasaur = [] \n",
        "pikachu = []\n",
        "\n",
        "image_height = 96\n",
        "image_width = 96\n",
        "channels = 3\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        if filename == \"Thumbs.db\":\n",
        "                continue\n",
        "        path = os.path.join(dirname, filename)\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img,(image_height,image_width), interpolation = cv2.INTER_AREA)\n",
        "        np_arr = np.asarray(img)\n",
        "        np_arr = np_arr.reshape(1,image_width*image_width*channels)\n",
        "        if dirname == \"/kaggle/input/dataset/charmander\":\n",
        "            charmander.append(np_arr)\n",
        "        elif dirname == \"/kaggle/input/dataset/squirtle\":\n",
        "            squirtle.append(np_arr)\n",
        "        elif dirname == \"/kaggle/input/dataset/mewtwo\":\n",
        "            mewtwo.append(np_arr)\n",
        "        elif dirname == \"/kaggle/input/dataset/bulbasaur\":\n",
        "            bulbasaur.append(np_arr)\n",
        "        elif dirname == \"/kaggle/input/dataset/pikachu\":\n",
        "            pikachu.append(np_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "kylnMsRshHhy",
        "colab_type": "code",
        "colab": {},
        "outputId": "a812a329-c761-4e6f-a54a-836635b15474"
      },
      "source": [
        "print(\"Number of mewtwo Images:      \" + str(len(mewtwo)))\n",
        "print(\"Number of pikachu Images:     \" + str(len(pikachu)))\n",
        "print(\"Number of squirtle Images:    \" + str(len(squirtle)))\n",
        "print(\"Number of bulbasaur Images:   \" + str(len(bulbasaur)))\n",
        "print(\"Number of charmander Images:  \" + str(len(charmander)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mewtwo Images:      239\n",
            "Number of pikachu Images:     234\n",
            "Number of squirtle Images:    223\n",
            "Number of bulbasaur Images:   234\n",
            "Number of charmander Images:  238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCaOFBqihHh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mewtwo_labels = np.zeros([len(mewtwo),1],dtype=int)\n",
        "pikachu_labels = np.ones([len(pikachu),1],dtype=int)\n",
        "squirtle_labels = np.ones([len(squirtle),1],dtype=int)*2\n",
        "bulbasaur_labels = np.ones([len(bulbasaur),1],dtype=int)*3\n",
        "charmander_labels = np.ones([len(charmander),1],dtype=int)*4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idZ-IkN_hHh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = charmander + squirtle + mewtwo + bulbasaur + pikachu\n",
        "Y = np.concatenate((charmander_labels , squirtle_labels , mewtwo_labels , bulbasaur_labels , pikachu_labels), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r56U5OqhHh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.asarray(X)\n",
        "X,Y = shuffle(X,Y)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.10, random_state=42)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train,Y_train, test_size=0.15, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdUJcjOchHiD",
        "colab_type": "code",
        "colab": {},
        "outputId": "7002d18b-273a-4e48-a872-14bb58bf08ea"
      },
      "source": [
        "print(\"Train Size:  \"+ str(len(X_train)))\n",
        "print(\"Validation Size:  \"+ str(len(X_val)))\n",
        "print(\"Test Size:  \"+ str(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Size:  893\n",
            "Validation Size:  117\n",
            "Test Size:  158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o52FozulhHiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "#changing uint8 pixel values to be b/w 0 and 1 \n",
        "X_train /= 255 \n",
        "X_test /= 255\n",
        "X_val /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOd7HvzKhHiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],channels,image_height,image_width)\n",
        "X_test = X_test.reshape(X_test.shape[0],channels,image_height,image_width)\n",
        "X_val = X_val.reshape(X_val.shape[0],channels,image_height,image_width)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z8ItrDEhHiP",
        "colab_type": "code",
        "colab": {},
        "outputId": "997f180d-b620-4c45-be74-89a6746b2a12"
      },
      "source": [
        "#Applying Augmentation techniques as dataset is small\n",
        "\n",
        "aug_X_train = []\n",
        "aug_Y_train = []\n",
        "for i in tqdm(range(X_train.shape[0])):\n",
        "    aug_X_train.append(X_train[i])\n",
        "    aug_X_train.append(rotate(X_train[i], angle=45, mode = 'wrap'))\n",
        "    aug_X_train.append(np.fliplr(X_train[i]))\n",
        "    aug_X_train.append(np.flipud(X_train[i]))\n",
        "    for j in range(4):\n",
        "        aug_Y_train.append(Y_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 893/893 [00:04<00:00, 216.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HHtEBmahHiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray(aug_X_train)\n",
        "Y_train = np.asarray(aug_Y_train)\n",
        "\n",
        "X_train,Y_train = shuffle(X_train,Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdbNcTlWhHiZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "291f0806-829c-4163-9947-821de316ecd5"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3572, 3, 96, 96)\n",
            "(3572, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-tvA0QyhHif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PokemnDataset(Dataset):\n",
        "    \"\"\"Five Pokemon dataset including [charmander + squirtle + mewtwo + bulbasaur + pikachu].\"\"\"\n",
        "    def __init__(self,X, Y):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            X (Images): Numpy array of Images. dimensions [num,3,96,96]\n",
        "            Y (Labels): Numpy array of Labels corresponding to Images. dimension [num]\n",
        "            \n",
        "        \"\"\"\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.Y = torch.from_numpy(Y)\n",
        "    \n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index \n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, label) \n",
        "        \"\"\"\n",
        "        img, label = self.X[index], int(self.Y[index])\n",
        "        \n",
        "        \"\"\"\n",
        "            img shape: [3,96,96]\n",
        "            label: int\n",
        "            \n",
        "        \"\"\"\n",
        "        return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRVrnEwohHil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = PokemnDataset(X_train,Y_train)\n",
        "val_set = PokemnDataset(X_val,Y_val)\n",
        "test_set = PokemnDataset(X_test,Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UCO2N9NhHir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=len(X_test), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODJo7RlBhHiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(27648,13824)\n",
        "        self.fc2 = nn.Linear(13824, 6912)\n",
        "        self.fc3 = nn.Linear(6912, 3456)\n",
        "        self.fc4 = nn.Linear(3456, 1728)\n",
        "        self.fc5 = nn.Linear(1728, 1024)\n",
        "        self.fc6 = nn.Linear(1024,5)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "       # Now with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))        \n",
        "        x = self.dropout(F.relu(self.fc4(x)))\n",
        "        x = self.dropout(F.relu(self.fc5(x)))\n",
        "              \n",
        "        \n",
        "        x = F.log_softmax(self.fc6(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjDbzaQVhHi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bUAwzSphHi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJstdQ8hHjB",
        "colab_type": "code",
        "colab": {},
        "outputId": "a842f408-0fef-4944-9bcd-6bdd2de3c21b"
      },
      "source": [
        "epochs = 50\n",
        "min_val_loss = 1000000 #used to update wieghts file for minimum loss weights only\n",
        "\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        images, labels = images.to(device), labels.to(device).long()\n",
        "        \n",
        "        log_ps = model(images.float())\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        val_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device).long()\n",
        "                log_ps = model(images.float())\n",
        "                val_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                \n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        val_losses.append(val_loss/len(val_loader))\n",
        "\n",
        "        \n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Validation Loss: {:.3f}.. \".format(val_loss/len(val_loader)),\n",
        "              \"Validation Accuracy: {:.3f}\".format(accuracy/len(val_loader)))\n",
        "        \n",
        "        if val_loss/len(val_loader) < min_val_loss:\n",
        "            min_val_loss = val_loss/len(val_loader)\n",
        "            torch.save(model.state_dict(), 'weights.pth')\n",
        "            print(\"Minimum Validation Loss updated. New Weights Saved\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50..  Training Loss: 76.346..  Validation Loss: 1.727..  Validation Accuracy: 0.185\n",
            "Minimum Validation Loss updated. New Weights Saved\n",
            "Epoch: 2/50..  Training Loss: 1.647..  Validation Loss: 1.695..  Validation Accuracy: 0.240\n",
            "Minimum Validation Loss updated. New Weights Saved\n",
            "Epoch: 3/50..  Training Loss: 1.637..  Validation Loss: 1.601..  Validation Accuracy: 0.208\n",
            "Minimum Validation Loss updated. New Weights Saved\n",
            "Epoch: 4/50..  Training Loss: 1.630..  Validation Loss: 1.599..  Validation Accuracy: 0.247\n",
            "Minimum Validation Loss updated. New Weights Saved\n",
            "Epoch: 5/50..  Training Loss: 1.624..  Validation Loss: 1.613..  Validation Accuracy: 0.240\n",
            "Epoch: 6/50..  Training Loss: 1.625..  Validation Loss: 1.614..  Validation Accuracy: 0.176\n",
            "Epoch: 7/50..  Training Loss: 1.653..  Validation Loss: 1.614..  Validation Accuracy: 0.165\n",
            "Epoch: 8/50..  Training Loss: 1.627..  Validation Loss: 1.614..  Validation Accuracy: 0.177\n",
            "Epoch: 9/50..  Training Loss: 1.623..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 10/50..  Training Loss: 1.638..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 11/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.169\n",
            "Epoch: 12/50..  Training Loss: 1.630..  Validation Loss: 1.626..  Validation Accuracy: 0.169\n",
            "Epoch: 13/50..  Training Loss: 1.615..  Validation Loss: 1.611..  Validation Accuracy: 0.180\n",
            "Epoch: 14/50..  Training Loss: 1.616..  Validation Loss: 1.615..  Validation Accuracy: 0.181\n",
            "Epoch: 15/50..  Training Loss: 2.734..  Validation Loss: 2.200..  Validation Accuracy: 0.177\n",
            "Epoch: 16/50..  Training Loss: 1.804..  Validation Loss: 1.613..  Validation Accuracy: 0.173\n",
            "Epoch: 17/50..  Training Loss: 1.624..  Validation Loss: 1.615..  Validation Accuracy: 0.169\n",
            "Epoch: 18/50..  Training Loss: 1.681..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 19/50..  Training Loss: 1.610..  Validation Loss: 1.614..  Validation Accuracy: 0.164\n",
            "Epoch: 20/50..  Training Loss: 1.619..  Validation Loss: 1.615..  Validation Accuracy: 0.160\n",
            "Epoch: 21/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.164\n",
            "Epoch: 22/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.169\n",
            "Epoch: 23/50..  Training Loss: 1.614..  Validation Loss: 1.613..  Validation Accuracy: 0.181\n",
            "Epoch: 24/50..  Training Loss: 2.038..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 25/50..  Training Loss: 1.670..  Validation Loss: 1.616..  Validation Accuracy: 0.160\n",
            "Epoch: 26/50..  Training Loss: 1.614..  Validation Loss: 1.615..  Validation Accuracy: 0.160\n",
            "Epoch: 27/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.177\n",
            "Epoch: 28/50..  Training Loss: 1.753..  Validation Loss: 1.613..  Validation Accuracy: 0.177\n",
            "Epoch: 29/50..  Training Loss: 1.615..  Validation Loss: 1.614..  Validation Accuracy: 0.164\n",
            "Epoch: 30/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 31/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.169\n",
            "Epoch: 32/50..  Training Loss: 1.616..  Validation Loss: 1.614..  Validation Accuracy: 0.160\n",
            "Epoch: 33/50..  Training Loss: 1.665..  Validation Loss: 1.613..  Validation Accuracy: 0.169\n",
            "Epoch: 34/50..  Training Loss: 1.730..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 35/50..  Training Loss: 1.609..  Validation Loss: 1.613..  Validation Accuracy: 0.181\n",
            "Epoch: 36/50..  Training Loss: 1.609..  Validation Loss: 1.613..  Validation Accuracy: 0.177\n",
            "Epoch: 37/50..  Training Loss: 1.610..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 38/50..  Training Loss: 1.609..  Validation Loss: 1.613..  Validation Accuracy: 0.173\n",
            "Epoch: 39/50..  Training Loss: 1.610..  Validation Loss: 1.613..  Validation Accuracy: 0.181\n",
            "Epoch: 40/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.169\n",
            "Epoch: 41/50..  Training Loss: 1.609..  Validation Loss: 1.613..  Validation Accuracy: 0.185\n",
            "Epoch: 42/50..  Training Loss: 1.615..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 43/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 44/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.169\n",
            "Epoch: 45/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.173\n",
            "Epoch: 46/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.160\n",
            "Epoch: 47/50..  Training Loss: 1.630..  Validation Loss: 1.601..  Validation Accuracy: 0.176\n",
            "Epoch: 48/50..  Training Loss: 1.609..  Validation Loss: 1.614..  Validation Accuracy: 0.160\n",
            "Epoch: 49/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.160\n",
            "Epoch: 50/50..  Training Loss: 1.609..  Validation Loss: 1.615..  Validation Accuracy: 0.156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uMBFHfbhHjH",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e2274ef-8d43-40f1-ffe3-60458995436e"
      },
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa282487128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH71JREFUeJzt3Xt0VPW99/H3dy5JFJAABrViD2p9rIAhpCnFB5Sb9fFSFS1WUSpaW5a2T2vL6arUx9ZL61poXUpxedrSKodVOVKO1sKxXmopFV09Bw2UIoiueEGlIMQLCnKdzPf5Y/ZMJslMMklmwJ18Xmtl7dl79t7z25PJZ3757pu5OyIiEn6RQ90AEREpDgW6iEgPoUAXEekhFOgiIj2EAl1EpIdQoIuI9BAFBbqZfc/MNpjZejN7yMwqzOx4M1tlZg1m9jszKyt1Y0VEJL8OA93MjgW+A9S5+wggClwG3AHc4+4nAR8A15SyoSIi0r5CSy4x4DAziwGHA1uBScDDwfMLgSnFb56IiBQq1tEM7v5PM7sLeAvYA/wJWA3scPdEMNtm4NiO1nXkkUf60KFDu95aEZFeaPXq1e+6e1VH83UY6GY2ALgQOB7YAfwncE6OWXNeQ8DMZgIzAT796U9TX1/f0UuKiEgWM3uzkPkKKbmcCbzh7o3ufgD4PfC/gcqgBAMwBNiSa2F3n+/ude5eV1XV4ReMiIh0USGB/hYwxswONzMDJgMvASuAqcE8M4ClpWmiiIgUosNAd/dVpHZ+rgFeDJaZD9wAzDKzV4FBwP0lbKeIiHSgwxo6gLvfDNzcavLrwOiit0hERLpEZ4qKiPQQCnQRkR5CgS4i0kOEItB/v2YzD/5PQYdhioj0WqEI9MfWbWXxC28d6maISCe999571NTUUFNTw9FHH82xxx6bGd+/f39B67j66qt55ZVX2p3nvvvuY9GiRcVoMuPGjWPt2rVFWdfBVtBRLodaeSzCvgPJQ90MEemkQYMGZcLxlltuoW/fvnz/+99vMY+74+5EIrn7lwsWLOjwdb71rW91v7E9QCh66OWxCPsSCnSRnuLVV19lxIgRXHvttdTW1rJ161ZmzpxJXV0dw4cP57bbbsvMm+4xJxIJKisrmT17NiNHjuS0005j+/btANx0003MnTs3M//s2bMZPXo0J598Mn/7298A+Pjjj/nyl7/MyJEjmTZtGnV1dR32xB988EFOPfVURowYwY033ghAIpHgq1/9amb6vHnzALjnnnsYNmwYI0eOZPr06UV/zwoRih56RTzKvkTToW6GSKjd+l8beGnLR0Vd57BPHcHN5w/v0rIvvfQSCxYs4Je//CUAc+bMYeDAgSQSCSZOnMjUqVMZNmxYi2U+/PBDxo8fz5w5c5g1axYPPPAAs2fPbrNud+f5559n2bJl3HbbbTz55JPce++9HH300TzyyCP84x//oLa2tt32bd68mZtuuon6+nr69+/PmWeeyWOPPUZVVRXvvvsuL774IgA7duwA4M477+TNN9+krKwsM+1gUw9dRA6JE088kc9//vOZ8Yceeoja2lpqa2vZuHEjL730UptlDjvsMM45J3VtwM997nNs2rQp57ovvvjiNvM899xzXHbZZQCMHDmS4cPb/yJatWoVkyZN4sgjjyQej3P55ZezcuVKPvOZz/DKK69w/fXX89RTT9G/f38Ahg8fzvTp01m0aBHxeLxT70WxhKKHXh6PqoYu0k1d7UmXSp8+fTKPGxoa+PnPf87zzz9PZWUl06dPZ+/evW2WKStrvjFaNBolkUi0mQegvLy8zTzuOS8Im1e++QcNGsS6det44oknmDdvHo888gjz58/nqaee4plnnmHp0qX89Kc/Zf369USj0U69ZneFqIfe1OlfiIiEw0cffUS/fv044ogj2Lp1K0899VTRX2PcuHEsWbIEgBdffDHnfwDZxowZw4oVK3jvvfdIJBIsXryY8ePH09jYiLtzySWXcOutt7JmzRqamprYvHkzkyZN4mc/+xmNjY3s3r276NvQkXD00GMRkg6JpBOP2qFujogUWW1tLcOGDWPEiBGccMIJjB07tuiv8e1vf5srr7yS6upqamtrGTFiRKZcksuQIUO47bbbmDBhAu7O+eefz3nnnceaNWu45pprcHfMjDvuuINEIsHll1/Ozp07SSaT3HDDDfTr16/o29ARO5i93rq6Ou/KDS5+vfJ1bn98I+tv/T/0LQ/Fd5CIfMIkEgkSiQQVFRU0NDRw1lln0dDQQCz2yc8UM1vt7nUdzffJ3xKgPJ6qDO070KRAF5Eu2bVrF5MnTyaRSODu/OpXvwpFmHdGKLamPBYEuo50EZEuqqysZPXq1Ye6GSUVkp2iqT3FCnQRkfxCEujpHrpOLhIRySccgZ6poauHLiKST4eBbmYnm9narJ+PzOy7ZjbQzJ42s4ZgOKBUjVTJRUSkY4XcJPoVd69x9xrgc8Bu4FFgNrDc3U8ClgfjJZEuuew9oJKLSJhMmDChzUlCc+fO5Zvf/Ga7y/Xt2xeALVu2MHXq1Lzr7ugw6Llz57Y4wefcc88tynVWbrnlFu66665ur6fYOltymQy85u5vAhcCC4PpC4EpxWxYNvXQRcJp2rRpLF68uMW0xYsXM23atIKW/9SnPsXDDz/c5ddvHeiPP/44lZWVXV7fJ11nA/0y4KHg8VHuvhUgGA7OtYCZzTSzejOrb2xs7FIjMzV07RQVCZWpU6fy2GOPsW/fPgA2bdrEli1bGDduXOa48NraWk499VSWLl3aZvlNmzYxYsQIAPbs2cNll11GdXU1l156KXv27MnMd91112UuvXvzzTcDMG/ePLZs2cLEiROZOHEiAEOHDuXdd98F4O6772bEiBGMGDEic+ndTZs2ccopp/CNb3yD4cOHc9ZZZ7V4nVzWrl3LmDFjqK6u5qKLLuKDDz7IvP6wYcOorq7OXBTsmWeeydzgY9SoUezcubPL720uBR+HbmZlwAXADzvzAu4+H5gPqTNFO9W6QOYoF+0UFem6J2bDOy8Wd51HnwrnzMn79KBBgxg9ejRPPvkkF154IYsXL+bSSy/FzKioqODRRx/liCOO4N1332XMmDFccMEFmOW+vMcvfvELDj/8cNatW8e6detaXP729ttvZ+DAgTQ1NTF58mTWrVvHd77zHe6++25WrFjBkUce2WJdq1evZsGCBaxatQp35wtf+ALjx49nwIABNDQ08NBDD/HrX/+ar3zlKzzyyCPtXt/8yiuv5N5772X8+PH8+Mc/5tZbb2Xu3LnMmTOHN954g/Ly8kyZ56677uK+++5j7Nix7Nq1i4qKis682x3qTA/9HGCNu28LxreZ2TEAwXB7UVuWRSUXkfDKLrtkl1vcnRtvvJHq6mrOPPNM/vnPf7Jt27a861m5cmUmWKurq6murs48t2TJEmpraxk1ahQbNmzo8MJbzz33HBdddBF9+vShb9++XHzxxTz77LMAHH/88dTU1ADtX6IXUtdn37FjB+PHjwdgxowZrFy5MtPGK664ggcffDBzRurYsWOZNWsW8+bNY8eOHUU/U7Uza5tGc7kFYBkwA5gTDNv+v1QkOg5dpAja6UmX0pQpU5g1axZr1qxhz549mZ71okWLaGxsZPXq1cTjcYYOHZrzkrnZcvXe33jjDe666y5eeOEFBgwYwFVXXdXhetq7hlX60ruQuvxuRyWXfP74xz+ycuVKli1bxk9+8hM2bNjA7NmzOe+883j88ccZM2YMf/7zn/nsZz/bpfXnUlAP3cwOB74I/D5r8hzgi2bWEDxXsk9Lcw1dPXSRsOnbty8TJkzga1/7WoudoR9++CGDBw8mHo+zYsUK3nzzzXbXc8YZZ2RuBL1+/XrWrVsHpC6926dPH/r378+2bdt44oknMsv069cvZ536jDPO4A9/+AO7d+/m448/5tFHH+X000/v9Lb179+fAQMGZHr3v/3tbxk/fjzJZJK3336biRMncuedd7Jjxw527drFa6+9xqmnnsoNN9xAXV0dL7/8cqdfsz0F9dDdfTcwqNW090gd9VJymZKLaugioTRt2jQuvvjiFke8XHHFFZx//vnU1dVRU1PTYU/1uuuu4+qrr6a6upqamhpGjx4NpO4+NGrUKIYPH97m0rszZ87knHPO4ZhjjmHFihWZ6bW1tVx11VWZdXz9619n1KhR7ZZX8lm4cCHXXnstu3fv5oQTTmDBggU0NTUxffp0PvzwQ9yd733ve1RWVvKjH/2IFStWEI1GGTZsWObuS8USisvnApz0/x7nG6efwA/OLt6/JyIiYVDo5XNDceo/pHrpKrmIiOQXokCPaKeoiEg7whXoqqGLiOQVnkCPq+QiItKe8AS6Si4iIu0KWaCrhy4ikk+IAj2qGrqISDvCE+hxlVxERNoTnkBXyUVEpF0hCnQd5SIi0p4QBbpKLiIi7QlPoMd1YpGISHvCE+ixqG4SLSLSjhAFunaKioi0J3SBfjAv9ysiEibhCfR46iYX+5vUSxcRyaXQW9BVmtnDZvaymW00s9PMbKCZPW1mDcFwQCkb2nxfUQW6iEguhfbQfw486e6fBUYCG4HZwHJ3PwlYHoyXTCbQdaSLiEhOHQa6mR0BnAHcD+Du+919B3AhsDCYbSEwpVSNhKz7iupYdBGRnArpoZ8ANAILzOzvZvYbM+sDHOXuWwGC4eBcC5vZTDOrN7P6xsbGLje0PK6Si4hIewoJ9BhQC/zC3UcBH9OJ8oq7z3f3Onevq6qq6mIzs3roKrmIiORUSKBvBja7+6pg/GFSAb/NzI4BCIbbS9PElOYeukouIiK5dBjo7v4O8LaZnRxMmgy8BCwDZgTTZgBLS9LCgI5yERFpX6zA+b4NLDKzMuB14GpSXwZLzOwa4C3gktI0MaV5p6gCXUQkl4IC3d3XAnU5nppc3Obk13zYokouIiK5hOZM0Qod5SIi0q7QBLpKLiIi7QtRoOsoFxGR9oQo0HUcuohIe8IT6Kqhi4i0KzSBXhZVyUVEpD2hCfRIxCiL6q5FIiL5hCbQIbhrkWroIiI5hSvQ4xH2quQiIpJTuAI9FlUPXUQkj5AFekQ7RUVE8ghVoJfFtFNURCSfUAV6eTyqQBcRySNcgR6L6GqLIiJ5hC/Q1UMXEckpVIFeoZKLiEheoQp0HeUiIpJfyAJdx6GLiORT0C3ozGwTsBNoAhLuXmdmA4HfAUOBTcBX3P2D0jQzpTyuGrqISD6d6aFPdPcad0/fW3Q2sNzdTwKWB+MlpZKLiEh+3Sm5XAgsDB4vBKZ0vzntK49pp6iISD6FBroDfzKz1WY2M5h2lLtvBQiGg3MtaGYzzazezOobGxu71djyWIT9iSTu3q31iIj0RAXV0IGx7r7FzAYDT5vZy4W+gLvPB+YD1NXVdSuJs+9aVBGPdmdVIiI9TkE9dHffEgy3A48Co4FtZnYMQDDcXqpGpmXuK6qyi4hIGx0Gupn1MbN+6cfAWcB6YBkwI5htBrC0VI1MK4/pNnQiIvkUUnI5CnjUzNLz/4e7P2lmLwBLzOwa4C3gktI1MyUT6DoWXUSkjQ4D3d1fB0bmmP4eMLkUjcqnPK6Si4hIPiE7U1QlFxGRfEIa6Oqhi4i0FrJAT5Vc9uqa6CIibYQr0OPqoYuI5BOuQNdRLiIieYUs0NNHuajkIiLSWsgCXSUXEZF8whXoqqGLiOQVrkBPl1x0lIuISBuhCvQK9dBFRPIKVaCXRRXoIiL5hCrQzUy3oRMRySNUgQ7BfUV1HLqISBvhC/S47isqIpJL+AJdJRcRkZxCGujqoYuItBbCQI+qhi4ikkPBgW5mUTP7u5k9Fowfb2arzKzBzH5nZmWla2az8rhKLiIiuXSmh349sDFr/A7gHnc/CfgAuKaYDctHJRcRkdwKCnQzGwKcB/wmGDdgEvBwMMtCYEopGthaeUxHuYiI5FJoD30u8AMgnaSDgB3ungjGNwPH5lrQzGaaWb2Z1Tc2NnarsZA+Dl0lFxGR1joMdDP7ErDd3VdnT84xq+da3t3nu3udu9dVVVV1sZnNyuNR9quHLiLSRqyAecYCF5jZuUAFcASpHnulmcWCXvoQYEvpmtlMNXQRkdw67KG7+w/dfYi7DwUuA/7i7lcAK4CpwWwzgKUla2WW8lhEN4kWEcmhO8eh3wDMMrNXSdXU7y9Ok9qnnaIiIrkVUnLJcPe/An8NHr8OjC5+k9qn49BFRHIL4ZmiEQ40OU3JnPtgRUR6rRAGeuo2dDrSRUSkpRAGevquRSq7iIhkC1+g676iIiI5hS7QK4KSi664KCLSUugCvbmHrpKLiEi28AV6uoeukouISAshDHT10EVEcglvoKuGLiLSQvgCPa6Si4hILuELdJVcRERyCnGgq4cuIpItfIEe13HoIiK5hC/QVXIREckpxIGuHrqISLYQBrqOchERySV0gR6PGmawT7ehExFpocNAN7MKM3vezP5hZhvM7NZg+vFmtsrMGszsd2ZWVvrmgpnpRtEiIjkU0kPfB0xy95FADXC2mY0B7gDucfeTgA+Aa0rXzJbKY1HdKFpEpJUOA91TdgWj8eDHgUnAw8H0hcCUkrQwB/XQRUTaKqiGbmZRM1sLbAeeBl4Ddrh7IphlM3BsaZrYVupG0Qp0EZFsBQW6uze5ew0wBBgNnJJrtlzLmtlMM6s3s/rGxsautzRLeSyq49BFRFrp1FEu7r4D+CswBqg0s1jw1BBgS55l5rt7nbvXVVVVdaetGeWxiM4UFRFppZCjXKrMrDJ4fBhwJrARWAFMDWabASwtVSNbUw1dRKStWMezcAyw0MyipL4Alrj7Y2b2ErDYzH4K/B24v4TtbKEirpKLiEhrHQa6u68DRuWY/jqpevpBVx6LsGtfouMZRUR6kdCdKQrBTlHV0EVEWghnoMcjKrmIiLQSzkDXTlERkTZCGuhRBbqISCshDfSIrrYoItJKOANdp/6LiLQRzkCPRUkknUSTQl1EJC2kgZ5q9n4FuohIRqgDXceii4g0C2egx3VfURGR1sIZ6Okeuk4uEhHJCGmgq4cuItJaSANdNXQRkdbCGejxVLP3quQiIpIRzkBPl1zUQxcRyQhpoGunqIhIa+EM9Hg60NVDFxFJC2egZ45yUQ9dRCStkJtEH2dmK8xso5ltMLPrg+kDzexpM2sIhgNK39wUHeUiItJWIT30BPCv7n4KMAb4lpkNA2YDy939JGB5MH5QVOhMURGRNjoMdHff6u5rgsc7gY3AscCFwMJgtoXAlFI1sjXtFBURaatTNXQzGwqMAlYBR7n7VkiFPjA4zzIzzazezOobGxu719qASi4iIm0VHOhm1hd4BPiuu39U6HLuPt/d69y9rqqqqittbCMWjRCNmEouIiJZCgp0M4uTCvNF7v77YPI2MzsmeP4YYHtpmphb6kbRKrmIiKQVcpSLAfcDG9397qynlgEzgsczgKXFb15+qUBXD11EJC1WwDxjga8CL5rZ2mDajcAcYImZXQO8BVxSmibmVh6LqoYuIpKlw0B39+cAy/P05OI2p3CpG0Wr5CIikhbKM0VBJRcRkdZCHOhRBbqISJYQB7pKLiIi2cIb6PGIdoqKiGQJb6Cr5CIi0kKIA10lFxGRbCEPdPXQRUTSQhzoUfYeUA9dRCQtvIEeVw9dRCRbeAM9pqNcRESyhTjQo+xLNOHuh7opIiKfCCEO9AhJh0RSgS4iAiEOdN1XVESkpdAGenk8fRs6HekiIgJhDvTMjaLVQxcRgVAHukouIiLZQhzo6R66Si4iIlDYPUUfMLPtZrY+a9pAM3vazBqC4YDSNrOt5hq6eugiIlBYD/3fgbNbTZsNLHf3k4DlwfhBpZKLiEhLHQa6u68E3m81+UJgYfB4ITClyO3qkEouIiItdbWGfpS7bwUIhoOL16TCZHroKrmIiAAHYaeomc00s3ozq29sbCzaejM1dJVcRESArgf6NjM7BiAYbs83o7vPd/c6d6+rqqrq4su1pZKLiEhLXQ30ZcCM4PEMYGlxmlM47RQVEWmpkMMWHwL+GzjZzDab2TXAHOCLZtYAfDEYP6gyPXSd+i8iAkCsoxncfVqepyYXuS2dohq6iEhLoT1TtCyqQBcRyRbaQI9FI8Qipp2iIiKB0AY6pOroe3UcuogIEPZAj0fVQxcRCYQ70HWjaBGRjPAHunaKiogAoQ90lVxERNJCHegVcfXQRUTSQh3o5bGoaugiIoFwB3o8opKLiEgg3IGunaIiIhkhD/SoAl1EJBDyQFfJRUQkrcOrLX6Slcd1YlF3rNu8g/krX+dAU5JLPnccE06uIhYN9Xe8SK8W7kBXyaXT3J3/ef19/u2vr7Kh4XXGVzRwWCTCDzacSPyIKi6tO46vfP44hgw4/FA3VUQ6KRyB/sGbcGA3RGJgkdQwEmVg8n0OS3wA+3dDrAIi6l3m4+48u/ZlVq1YxuD3X+Dm2Ct8puKt1JNJoALe9qH85dn/xe3PDCMydCzja05h8BHlDOxTxoDDyxjQp4w+ZVHMrM26DzQ5B5qSxKJGWTTSZp6DYff+BK+8s5OX39nJy1s/YuM7O3nlnZ3Eo8YJVX05saovJ1b14cTBfflMVV+O7l9BLGKdbqu7s+dAEx/tSfDR3gPs3JugLBqhX0Us+IlTFjs4n0V3Z18iyf6mJPsTWT9NSSIGfcpj9C2P0acsRiRy8H8ncnCZux+0F6urq/P6+vrOL7joEmj4U4ez7fEy9lLOXsrYa2V41i6C9FZa5scxnEgwNDp6H1LPp98uD9aRWqdlVt7ZP5nsV7XWj9Or9eY2tm5rkggOzVuSFU6W9buN0MRRvA/AgehhRP7lNKLHj4Ohp6dm2PQcbHqO5Fv/TeTAbgC2+ECSOXazRILXcAdv530zs8z7jbXa2LwLFTBPa8F6E9782Azi0Qhl0dQKDzQlSSSdZKvPu2UNLfNrDN7hHG1xp8068omYNa+iq1ma9VLJ4E3M9RkshGGYpbczV4O6kgX5NqwIudJ6FSX8Psr8ZXnqfU6PB590IkCEZPA3XkhetJX86lKOPWF4l9pnZqvdva6j+cLRQx83C0ZOA09CsgmSCfAm3t+1h9WvbyfatIdY015iTXuJJ/cQS+4lntyX9YHIevPdcWsdj5HgDzj/Jyb1B2+ZP/x0r85JB1tqJOntRVzqTzATIpY9lrWsO8lgvbgHM0aah5llgi8UT4I7RrL5Gyc9R9BOA7Yf/VlOOe1c4kNqIRpv2bTjRsPps4g0HYAta0m+8Sz9tmxkX6KJ/YlkqhfYqvcXMUv9RJofJz0Vmk1JJ5mEJneSySROcztaf/Gl37sWLW8vNHP8niI4h5fHqDwsTv/D4hze4j+J5vn3JZrYua+JnXsPsOdAkmQQ8sngd5d0x5P5f4exiFEWixCPRohHLTWMGElSXxrp/1TSj5P51tWJ7Ut3QCIRy3wOo2apf1YxLGJEI6n3P2oQCR67QyKZJNHkHAiGiWSSpqbOvbd5ubc7u+dK4E7+Xlt+0gtcTxeYkdW5g4glUx0iS4d8KiOSQZS7d/7b5fiKvkVtcy7d6qGb2dnAz4Eo8Bt3b/feol3uoYuI9GKF9tC7XOgzsyhwH3AOMAyYZmbDuro+ERHpnu7suRkNvOrur7v7fmAxcGFxmiUiIp3VnUA/Fng7a3xzMK0FM5tpZvVmVt/Y2NiNlxMRkfZ0J9AL2k3u7vPdvc7d66qqqrrxciIi0p7uBPpm4Lis8SHAlu41R0REuqo7gf4CcJKZHW9mZcBlwLLiNEtERDqry8ehu3vCzP4v8BSpwxYfcPcNRWuZiIh0SrdOLHL3x4HHi9QWERHphoN66r+ZNQJvdnHxI4F3i9icsNB29y69dbuh9257Idv9L+7e4VElBzXQu8PM6gs5U6qn0Xb3Lr11u6H3bnsxt1uXJxQR6SEU6CIiPUSYAn3+oW7AIaLt7l1663ZD7932om13aGroIiLSvjD10EVEpB2hCHQzO9vMXjGzV81s9qFuT6mY2QNmtt3M1mdNG2hmT5tZQzAccCjbWApmdpyZrTCzjWa2wcyuD6b36G03swoze97M/hFs963B9OPNbFWw3b8LzsTuccwsamZ/N7PHgvEev91mtsnMXjSztWZWH0wr2uf8Ex/ovey66/8OnN1q2mxgubufBCwPxnuaBPCv7n4KMAb4VvA77unbvg+Y5O4jgRrgbDMbA9wB3BNs9wfANYewjaV0PbAxa7y3bPdEd6/JOlSxaJ/zT3yg04uuu+7uKyG48WezC4GFweOFwJSD2qiDwN23uvua4PFOUn/kx9LDt91TdgWj8eDHgUnAw8H0HrfdAGY2BDgP+E0wbvSC7c6jaJ/zMAR6Qddd78GOcvetkAo+YPAhbk9JmdlQYBSwil6w7UHZYS2wHXgaeA3Y4e6JYJae+nmfC/wASAbjg+gd2+3An8xstZnNDKYV7XMehptEF+v25PIJZ2Z9gUeA77r7R9aZGxaHlLs3ATVmVgk8CpySa7aD26rSMrMvAdvdfbWZTUhPzjFrj9ruwFh332Jmg4GnzezlYq48DD303n7d9W1mdgxAMNx+iNtTEmYWJxXmi9z998HkXrHtAO6+A/grqX0IlWaW7mz1xM/7WOACM9tEqoQ6iVSPvadvN+6+JRhuJ/UFPpoifs7DEOi9/brry4AZweMZwNJD2JaSCOqn9wMb3f3urKd69LabWVXQM8fMDgPOJLX/YAUwNZitx223u//Q3Ye4+1BSf89/cfcr6OHbbWZ9zKxf+jFwFrCeIn7OQ3FikZmdS+obPH3d9dsPcZNKwsweAiaQuvraNuBm4A/AEuDTwFvAJe7eesdpqJnZOOBZ4EWaa6o3kqqj99htN7NqUjvBoqQ6V0vc/TYzO4FUz3Ug8HdgurvvO3QtLZ2g5PJ9d/9ST9/uYPseDUZjwH+4++1mNogifc5DEegiItKxMJRcRESkAAp0EZEeQoEuItJDKNBFRHoIBbqISA+hQBcR6SEU6CIiPYQCXUSkh/j/+052VTBZFVQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8T7CM-phHjQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "c0692eee-0fd8-45f9-b6f1-1a83039d1190"
      },
      "source": [
        "#load the best weights\n",
        "state_dict = torch.load('weights.pth')\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGsUJ95uhHjW",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e744fbe-f0ee-479c-aaea-175d42beb32b"
      },
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "# Get the class probabilities\n",
        "images, labels = images.to(device), labels.to(device).long()\n",
        "ps = torch.exp(model(images.float()))\n",
        "\n",
        "top_p, top_class = ps.topk(1, dim=1)\n",
        "equals = top_class == labels.view(*top_class.shape)\n",
        "\n",
        "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
        "print(f' Test Accuracy: {accuracy.item()*100}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Test Accuracy: 25.316455960273743%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}